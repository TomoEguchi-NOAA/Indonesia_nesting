
---
title: "Combining data imputation and trend analysis using discrete Fourier series"
output: html_notebook
---

Trying to merge the data imputation process and trend analysis with multiple datasets.

Model names were changed to streamline file names. Also added modified versions of models. In the new models (v2), the middle "state" space (x) is eliminated. Nt is modeled as a random variable, then Nt is divided into each month (X but not treated as a random variable), then y is observed from each X.

Set things up:

```{r}
rm(list=ls())

# tic <- Sys.time()
# Sys <- Sys.info()
source('Dc_Indonesia_nesting_fcns.R')
#library(rjags)

library(jagsUI)
library(coda)
library(tidyverse)
library(loo)
```


```{r}
save.data <- T
save.fig <- T
run.date <- "2020-10-14" #Sys.Date() #"2019-06-25" #

year.begin.JM <- 1999
year.begin.W <- 2006
#year.begin <- 2002
year.end <- 2019

period.JM <- 12
period.W <- 6
maxN <- 10000

UQ.models <- c("1U_1Q", 
               "1U_2Q",
               "2U_1Q",
               "2U_2Q")

# t_loc has location (or series) specific df parameter 
state.models <- c("norm", "t")
obs.models <- c("norm", "t") # 
v.models <- c("DFS_v1", "DFS_v2")  # v2 models have no Xs - Ns are the state

```


Set up the MCMC parameters

```{r}
MCMC.n.chains <- 5
MCMC.n.samples <- 50000
MCMC.n.burnin <- 10000
MCMC.n.thin <- 5

MCMC.params <- list(n.chains = MCMC.n.chains,
                    n.samples = MCMC.n.samples,
                    n.burnin = MCMC.n.burnin,
                    n.thin = MCMC.n.thin)
```


Bring in the data

```{r}
# Beginning year for JM is 1999
data.jags.JM <- data.extract(location = "JM", 
                             year.begin = year.begin.JM, 
                             year.end = year.end)

# Begining year for Wermon is 2006.
data.jags.W <- data.extract(location = "W", 
                             year.begin = year.begin.W, 
                             year.end = year.end)

```

Get warnings but they are harmless - I think. 

Combine datasets for analysis

```{r}
y <- array(data= NA, dim = c(nrow(data.jags.JM$jags.data2$y),
                             ncol(data.jags.JM$jags.data2$y), 2))
y[,,1] <- data.jags.JM$jags.data2$y
y[,,2] <- rbind(matrix(NA, nrow = nrow(data.jags.JM$jags.data2$y) - 
                         nrow(data.jags.W$jags.data2$y), ncol = 12),
                data.jags.W$jags.data2$y)

jags.data <- list(y = y,
                  #m = data.jags.JM$jags.data2$m,
                  C0 = c(15, 15),
                  n.months = 12,
                  C_cos = c(sum(apply(matrix(1:12, nrow=1), 
                                      MARGIN = 1, 
                                      FUN = function(x) cos(2 * pi * x/period.JM))), 
                            sum(apply(matrix(1:12, nrow=1), 
                                      MARGIN = 1, 
                                      FUN = function(x) cos(2 * pi * x/period.W)))),
                  C_sin = c(sum(apply(matrix(1:12, nrow=1), 
                                      MARGIN = 1, 
                                      FUN = function(x) sin(2 * pi * x/period.JM))),
                            sum(apply(matrix(1:12, nrow=1), 
                                      MARGIN = 1, 
                                      FUN = function(x) sin(2 * pi * x/period.W)))),
                  pi = pi,
                  period = c(period.JM, period.W),
                  N0_mean = c(8,8),   # this is 2980.958. Should be close enough
                  N0_sd = c(10, 10),
                  n.states = 2)

#n.timeseries <- dim(y)[3]

#jags.data$n.timeseries <- n.timeseries
jags.data$n.years <- dim(y)[1]

# jags.data$q_alpha <- 2
# jags.data$q_beta <- 0.5
# jags.data$r_alpha <- 2
# jags.data$r_beta <- 0.5

```

run jags on each model
```{r}
c <- 1
loo.out <- list()
filenames <- list()
k1 <- k2 <- 1
for (k1 in 1:length(UQ.models) ){ #3:()
  UQ.model <- UQ.models[k1]
  for (k2 in 1:length(obs.models)){
    obs.model <- obs.models[k2]
    for (k3 in 1:length(state.models)){
      state.model <- state.models[k3]
      for (k4 in 1:length(v.models)){
        v.model <- v.models[k4]
        filename.root <- paste0("SSAR1_", state.model, "_", 
                                obs.model, "_trend_", 
                                v.model, "_",
                                UQ.model, "_",
                                "JM", period.JM, 
                                "_W", period.W, "_",
                                year.begin.JM, "_", 
                                year.end, "_", run.date)
        
        filenames[[c]] <- filename.root
        # define parameters to monitor - add "df" for t distribution
        jags.params <- c('N', 'U', "p", "p.beta.cos", "p.beta.sin",
                         "sigma.Q", "sigma.R", 
                         "mu", "y", "deviance", "loglik")
        
        if (v.model == "DFS_v1"){
          jags.params <- c(jags.params, "X")
        }
        
        if (obs.model == "t"){
          jags.params <- c(jags.params, "df.y")
        }
        
        if (state.model == "t"){
          jags.params <- c(jags.params, "df.X")
        }
        
        model.name <- paste0("models/trend_models/model_", 
                             state.model, "_", obs.model, 
                             "_trend_", v.model, "_", 
                             UQ.model, ".txt")
        
        if (file.exists(model.name)){
          
          print(paste0("Running: ", model.name))
          
          if (!file.exists(paste0("RData/", filename.root, '.rds'))){
            jm <- jags(jags.data,
                       inits = NULL,
                       parameters.to.save= jags.params,
                       model.file = model.name,
                       n.chains = MCMC.params$n.chains,
                       n.burnin = MCMC.params$n.burnin,
                       n.thin = MCMC.params$n.thin,
                       n.iter = MCMC.params$n.samples,
                       DIC = T, parallel=T)
            
            saveRDS(jm,
                    file = paste0("RData/", filename.root, '.rds'))
          } else {
            jm <- readRDS(file = paste0("RData/", filename.root, '.rds'))
          }
          
          if (!file.exists(paste0("RData/", filename.root, "_loo.rds"))){
            loo.out[[c]] <- compute.LOOIC(loglik = jm$sims.list$loglik, 
                                          MCMC.params = MCMC.params, 
                                          data.vector = as.vector(jags.data$y))
            saveRDS(loo.out[[c]], file = paste0("RData/", filename.root, "_loo.rds"))
          } else {
            loo.out[[c]] <- readRDS(file = paste0("RData/", filename.root, "_loo.rds"))
            
          }
          
          c <- c + 1
          
        } else {
          print(paste0("Model file ", model.name, " does not exist" ))
        }    
        
      }
      
    }
    
  }
}

```

First look at the Pareto k diagnostics first to see how the models fit.

```{r}
pareto.k <- lapply(loo.out, 
                   FUN = function(x) x$loo.out)

# These have been saved so commenting out 2020-10-15
#saveRDS(loo.out, file = "RData/loo_all_Oct2020.rds")
#saveRDS(filenames, file = "RData/filenames_Oct2020.rds")

# find maximum pareto k values
max.pareto.k <- unlist(lapply(pareto.k,
       FUN = function(x) max(x$diagnostics$pareto_k)))

# find the models that have max(pareto k) < 0.7
good.models <- filenames[which(max.pareto.k < 0.7)]
good.models.pareto.k <- pareto.k[which(max.pareto.k < 0.7)]
```


Compare the results using LOOIC:

```{r}
looic.esimates <- lapply(lapply(loo.out[which(max.pareto.k < 0.7)], 
                                FUN = function(x) x$loo.out),
                         FUN = function(x) x$estimates)

looic <- unlist(lapply(looic.esimates, 
                       FUN = function(x) x["looic", "Estimate"]))

loo.out.list <- lapply(loo.out[which(max.pareto.k < 0.7)], 
                       FUN = function(x) x$loo.out)

# calculate model weights
model.weights <- loo_model_weights(loo.out.list)

model.names.abb <- lapply(good.models, 
                          FUN = function(x) strsplit(x, split = "SSAR1_")[[1]][2]) %>%  
  lapply(FUN = function(x) strsplit(x, split = "_JM12")[[1]][1]) %>% unlist() 

options(scipen = 999)

looic.table <- data.frame(model = model.names.abb,
                          looic = looic,
                          weights = as.vector(model.weights)) %>% 
  arrange(by = desc(weights)) %>%
  mutate(delta.looic = looic - min(looic)) %>%
  mutate_if(is.numeric, round, digits = 4)

best.model <- good.models[which(looic == min(looic))]
pareto.k.best <- good.models.pareto.k[[which(looic == min(looic))]]
```




Below, I look at less preferred models - not much difference for some and some difference in some... 

```{r}
okay.models <- good.models[which(looic < (min(looic) + 3))]
```


According to the LOOIC values, normal process and t observation models with N as the random variable, a common slope and independent variance terms (norm_t_trend_DFS_v2_1U_2Q) was considered best. 

Take a look at all data points vs. pareto k

```{r}

data.jags.JM$data.1 %>% select(Frac.Year, Nests, Season) %>%
  mutate(Loc = "JM") %>%
  # transmute(Frac.Year = Frac.Year,
  #           Nests.JM = Nests,
  #           Season = Season) %>% 
  na.omit() -> data.JM

data.jags.W$data.1 %>% select(Frac.Year, Nests, Season) %>%
  mutate(Loc = "W") %>%
  # transmute(Frac.Year = Frac.Year, 
  #           Nests.W = Nests) %>%
  na.omit() -> data.W

data.loo <- rbind(data.JM, data.W)
# n.JM <- nrow(data.JM)
# n.both <- n.JM + nrow(data.W)
data.loo$pareto.k <- pareto.k.best$diagnostics$pareto_k

ggplot(data = data.loo) + 
  geom_point(aes(x = Frac.Year, y = pareto.k, color = Loc))
```

Pareto k values are worse for the Wermon dataset than for the JM dataset. But, they are fine. 

Look at the convergence:
```{r}
jm <- readRDS(file = paste0("RData/", best.model[[1]], ".rds"))
max(unlist(lapply(jm$Rhat, FUN = max, na.rm = T)))

```


Let's look at the posteriors of parameters.

```{r}
# p.post.U <- bayesplot::mcmc_dens(jm$samples, c("U")) + 
#   xlab("Annual growth rate") + ylab("Density")

bayesplot::mcmc_dens(jm$samples, c("U[1]", "U[2]"))
```


```{r}
data.frame(jm$summary) %>% rownames_to_column("Parameter") -> summary.df

#summary.df[grep(summary.df$Parameter, pattern = "U\\["),]
summary.df[grep(summary.df$Parameter, pattern = "U"),]
```


```{r}
bayesplot::mcmc_dens(jm$samples, c("sigma.Q[1]", "sigma.Q[2]"))
```


```{r}
summary.df[grep(summary.df$Parameter, pattern = "sigma.Q"),]

```


Get posterior summary out.

```{r}

out.best.model <- plot.results(jm, data.jags.JM = data.jags.JM, data.jags.W = data.jags.W)

out.best.model$p.results
```

Take a look at okay models. 

```{r}
jm <- readRDS(file = paste0("RData/", okay.models[[1]], ".rds"))
max(unlist(lapply(jm$Rhat, FUN = max, na.rm = T)))

```

```{r}
data.frame(jm$summary) %>% rownames_to_column("Parameter") -> summary.df

#summary.df[grep(summary.df$Parameter, pattern = "U\\["),]
summary.df[grep(summary.df$Parameter, pattern = "U"),]

```

```{r}
out.okay.model.1 <- plot.results(jm, data.jags.JM = data.jags.JM, data.jags.W = data.jags.W)

out.okay.model.1$p.results

```

#5 okay model:

```{r}
jm <- readRDS(file = paste0("RData/", okay.models[[5]], ".rds"))
max(unlist(lapply(jm$Rhat, FUN = max, na.rm = T)))

```

```{r}
data.frame(jm$summary) %>% rownames_to_column("Parameter") -> summary.df

#summary.df[grep(summary.df$Parameter, pattern = "U\\["),]
summary.df[grep(summary.df$Parameter, pattern = "U"),]

```

This is a little different. A positive growth rate for Wermon. 

```{r}
bayesplot::mcmc_dens(jm$samples, c("U[1]", "U[2]"))

```


```{r}
out.okay.model.5 <- plot.results(jm, data.jags.JM = data.jags.JM, data.jags.W = data.jags.W)

out.okay.model.5$p.results

```



#8 okay model:

```{r}
jm <- readRDS(file = paste0("RData/", okay.models[[8]], ".rds"))
max(unlist(lapply(jm$Rhat, FUN = max, na.rm = T)))

```

```{r}
data.frame(jm$summary) %>% rownames_to_column("Parameter") -> summary.df

#summary.df[grep(summary.df$Parameter, pattern = "U\\["),]
summary.df[grep(summary.df$Parameter, pattern = "U"),]

```



```{r}
bayesplot::mcmc_dens(jm$samples, c("U[1]", "U[2]"))

```


```{r}
out.okay.model.8 <- plot.results(jm, data.jags.JM = data.jags.JM, data.jags.W = data.jags.W)

out.okay.model.8$p.results

```




Look at how the "bad" models performed

```{r}

bad.models <- filenames[which(max.pareto.k >= 0.7)]
bad.models.pareto.k <- pareto.k[which(max.pareto.k >= 0.7)]
```


Compare the results using LOOIC:

```{r}
bad.looic.esimates <- lapply(lapply(loo.out[which(max.pareto.k >= 0.7)], 
                                FUN = function(x) x$loo.out),
                         FUN = function(x) x$estimates)

bad.looic <- unlist(lapply(bad.looic.esimates, 
                       FUN = function(x) x["looic", "Estimate"]))

best.bad.model <- bad.models[which(looic == min(looic))]
pareto.k.best.bad <- bad.models.pareto.k[[which(looic == min(looic))]]

```


```{r}
jm <- readRDS(file = paste0("RData/", best.bad.model[[1]], ".rds"))
max(unlist(lapply(jm$Rhat, FUN = max, na.rm = T)))

```

Convergence was not a problem.

```{r}
data.frame(jm$summary) %>% rownames_to_column("Parameter") -> summary.df

#summary.df[grep(summary.df$Parameter, pattern = "U\\["),]
summary.df[grep(summary.df$Parameter, pattern = "U"),]

```

```{r}
summary.df[grep(summary.df$Parameter, pattern = "sigma.Q"),]
```


```{r}
out.bad.model <- plot.results(jm, data.jags.JM = data.jags.JM, data.jags.W = data.jags.W)

out.bad.model$p.results

```


This does look worse than the results from the "good" models above. I guess I feel better about selecting the "best" model. 
